{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d88acb3",
   "metadata": {},
   "source": [
    "# 网络爬虫工具练习题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7524f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61821e0",
   "metadata": {},
   "source": [
    "# 练习1：使用 socket 获取网页内容\n",
    "编写代码，使用 socket 模块连接到 \"www.baidu.com\"，发送 HTTP 请求并接收响应，最后打印响应内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc05c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 socket 连接并发送 HTTP 请求\n",
    "def fetch_with_socket():\n",
    "  host = '' # TODO, 访问百度首页\n",
    "  port = 80\n",
    "  with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    s.connect((host, port))\n",
    "    request = f\"GET / HTTP/1.1\\r\\nHost: {host}\\r\\n\\r\\n\"\n",
    "    s.send(request.encode())\n",
    "    response = b''\n",
    "    while True:\n",
    "      data = s.recv(4096)\n",
    "      if not data:\n",
    "        break\n",
    "      response += data\n",
    "    # 分割响应头和响应体\n",
    "    header_end = response.find(b'\\r\\n\\r\\n')\n",
    "    if header_end != -1:\n",
    "      response = response[header_end + 4:]\n",
    "    return response.decode()\n",
    "\n",
    "fetch_with_socket()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cda9a7e",
   "metadata": {},
   "source": [
    "# 练习2：使用 urllib.request 获取网页内容\n",
    "编写代码，使用 urllib.request 模块获取 \"http://www.baidu.com\" 的网页内容并打印。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dba397",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# 使用 urllib.request 获取网页内容\n",
    "def fetch_with_urllib():\n",
    "  with urllib.request.urlopen('http://www.baidu.com') as response:\n",
    "    return response.read(). # TODO  对内容对象进行解码\n",
    "\n",
    "fetch_with_urllib()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2096a9",
   "metadata": {},
   "source": [
    "# 练习3：比较 socket 和 urllib.request 获取的内容\n",
    "修改前面两个函数，将获取的网页内容保存到变量中，比较两者的内容是否一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8a801",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compare_contents():\n",
    "  socket_content = fetch_with_socket()\n",
    "  urllib_content = fetch_with_urllib()\n",
    "  print(\"内容是否一致：\", socket_content == urllib_content)\n",
    "\n",
    "compare_contents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba920531",
   "metadata": {},
   "source": [
    "# 练习4：使用 bs4.BeautifulSoup 解析网页内容\n",
    "使用 socket 获取 \"www.baidu.com\" 的网页内容，并使用 BeautifulSoup 提取并打印网页中的所有链接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cb65d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 使用 socket 获取网页内容并解析\n",
    "def parse_with_beautifulsoup():\n",
    "  content = fetch_with_socket()\n",
    "  soup = BeautifulSoup(content, '')  # TODO，添加解析器\n",
    "  for link in soup.find_all('a'):\n",
    "    print(link.get('href'))\n",
    "\n",
    "parse_with_beautifulsoup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd72f45",
   "metadata": {},
   "source": [
    "# 练习5：使用 urllib.request 和 bs4.BeautifulSoup 提取特定信息\n",
    "使用 urllib.request 获取 \"http://www.baidu.com\" 的网页内容，并使用 BeautifulSoup 提取并打印网页中的所有链接。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c512740",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_links_with_urllib():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, '')  # TODO， 同样，添加解析器\n",
    "  for link in soup.find_all('a'):\n",
    "    print(link.get('href'))  \n",
    "\n",
    "extract_links_with_urllib()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60220c83",
   "metadata": {},
   "source": [
    "# 练习6：比较 socket 和 urllib.request 解析后的内容\n",
    "修改前面两个解析函数，提取相同网页中的所有链接，比较两者提取的链接是否一致。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6658c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compare_links():\n",
    "  content1 = fetch_with_socket()\n",
    "  content2 = fetch_with_urllib()\n",
    "  soup1 = BeautifulSoup(content1, 'html.parser')\n",
    "  soup2 = BeautifulSoup(content2, 'html.parser')\n",
    "  links1 = [link.get('href') for link in soup1.find_all('a')]\n",
    "  links2 = [link.get('href') for link in soup2.find_all('a')]\n",
    "  print(\"链接是否一致：\", links1 == links2)\n",
    "\n",
    "compare_links()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1df487",
   "metadata": {},
   "source": [
    "# 练习7：使用 bs4.BeautifulSoup 提取特定标签的内容\n",
    "使用 urllib.request 获取 \"http://www.baidu.com\" 的网页内容，并使用 BeautifulSoup 提取并打印网页中特定标签（如 h1）的文本内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c0071",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_h1_with_beautifulsoup():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  h1_tags = soup.find_all('',attrs={'class': 'title-content-title'})    # TODO， 查找span标签\n",
    "  for tag in h1_tags:\n",
    "    print(tag.text)\n",
    "\n",
    "extract_h1_with_beautifulsoup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f861315",
   "metadata": {},
   "source": [
    "# 练习8：综合练习 - 爬取并解析网页\n",
    "编写一个程序，使用 urllib 获取 \"www.baidu.com\" 的网页内容，使用 BeautifulSoup 解析，并将所有链接保存到文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c98c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_links_to_file():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  links = [link.get('href') for link in soup.find_all('a')]\n",
    "  with open('', 'w') as f:   # TODO， 存到文件\"baidu.txt\"里\n",
    "    for link in links:\n",
    "      f.write(link + '\\n')\n",
    "\n",
    "save_links_to_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485db870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "jupyter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
