{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec28dc0",
   "metadata": {},
   "source": [
    "# 网络爬虫工具练习题-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace91b10",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ce006",
   "metadata": {},
   "source": [
    "# 练习1: 用 urllib.request 获取网页www.baidu.com的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f9adb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fetch_with_urllib():\n",
    "  url = ''  # TODO \n",
    "  with urllib.request.urlopen('http://'+url) as response:\n",
    "    return response.read().decode()\n",
    "\n",
    "print(fetch_with_urllib())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d989316",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# 练习2: 修改url为sohu的24小时热点\n",
    "## url为`www.sohu.com/xtopic/TURBd01ERTJNRE13`\n",
    "## 检查是否被拒绝访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77236424",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "def fetch_with_urllib():\n",
    "  url = ''  # TODO\n",
    "  with urllib.request.urlopen('http://'+url) as response:\n",
    "    return response.read().decode()\n",
    "\n",
    "print(fetch_with_urllib())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a8d11",
   "metadata": {},
   "source": [
    "# 练习3: 添加headers，构建Request对象.\n",
    "## 检查是否可以正常访问"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba970fd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fetch_with_urllib():\n",
    "  url = 'www.sohu.com/xtopic/TURBd01ERTJNRE13' # TODO\n",
    "  headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'\n",
    "  }\n",
    "  req = urllib.request.Request('http://'+url, headers=headers)\n",
    "  with urllib.request.urlopen(req) as response:\n",
    "    return response.read().decode()\n",
    "\n",
    "print(fetch_with_urllib())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a08412f",
   "metadata": {},
   "source": [
    "# 练习4：使用 BeautifulSoup 提取特定标签的属性\n",
    "## 使用 urllib.request 获取 \"http://www.sohu.com/xtopic/TURBd01ERTJNRE13\" 的网页内容，并使用 BeautifulSoup 提取并打印所有 `<span>` 标签的 `string` 属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390c3d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def extract_h1_with_beautifulsoup():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  span_tags = soup.find_all('')      # TODO\n",
    "  for tag in span_tags:\n",
    "    print(tag.string)\n",
    "\n",
    "extract_h1_with_beautifulsoup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d4b90b",
   "metadata": {},
   "source": [
    "# 练习5：使用 BeautifulSoup 查找特定类名的标签\n",
    "## 使用 urllib.request 获取 \"http://www.sohu.com/xtopic/TURBd01ERTJNRE13\" 的网页内容，并使用 BeautifulSoup 查找并打印所有具有特定类名 `CompTPLTopFeed`的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e980903",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def find_tags_by_class_with_beautifulsoup():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  tags = soup.find_all(class_='CompTPLTopFeed')    \n",
    "  for tag in :  # TODO\n",
    "    print(tag)\n",
    "\n",
    "find_tags_by_class_with_beautifulsoup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e812d96",
   "metadata": {},
   "source": [
    "# 练习6：使用 BeautifulSoup 查找特定 ID 的标签\n",
    "## 使用 urllib.request 获取 \"http://www.sohu.com/xtopic/TURBd01ERTJNRE13\" 的网页内容，并使用 BeautifulSoup 查找并打印具有特定 ID（如 `block2`）的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c58e78",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def find_tag_by_id_with_beautifulsoup():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  tag = soup.find()   # TODO\n",
    "  print(tag)\n",
    "\n",
    "find_tag_by_id_with_beautifulsoup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef76cfeb",
   "metadata": {},
   "source": [
    "# 练习7：使用 BeautifulSoup 查找父标签\n",
    "## 使用 urllib.request 获取 \"http://www.sohu.com/xtopic/TURBd01ERTJNRE13\" 的网页内容，并使用 BeautifulSoup 查找并打印某个特定标签（如 `<script>`）的所有父标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5cd188",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def find_parent_tags_with_beautifulsoup():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  p_tag = soup.find('')   # TODO\n",
    "  if p_tag:\n",
    "    for parent in p_tag.parents:\n",
    "      print(parent)\n",
    "\n",
    "find_parent_tags_with_beautifulsoup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2ffd7",
   "metadata": {},
   "source": [
    "# 练习8：使用 BeautifulSoup 查找兄弟标签\n",
    "## 使用 urllib.request 获取 \"http://www.sohu.com/xtopic/TURBd01ERTJNRE13\" 的网页内容，并使用 BeautifulSoup 查找并打印 `<script>`）的所有兄弟标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85045c65",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def find_sibling_tags_with_beautifulsoup():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  p_tag = soup.   # TODO\n",
    "  if p_tag:\n",
    "    for sibling in p_tag.next_siblings:\n",
    "      print(sibling)\n",
    "    for sibling in p_tag.previous_siblings:\n",
    "      print(sibling)\n",
    "\n",
    "find_sibling_tags_with_beautifulsoup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac05d422",
   "metadata": {},
   "source": [
    "# 练习9：使用 BeautifulSoup 获取指定标签里的内容。\n",
    "## 使用 urllib.request 获取 \"http://www.sohu.com/xtopic/TURBd01ERTJNRE13\" 的网页内容，并使用 BeautifulSoup 将 `<div>`里的`class`为`title`的内容提取出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287693df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parent_tags_with_beautifulsoup():\n",
    "  content = fetch_with_urllib()\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "  p_tag = soup.find_all('div', attrs={'class': ''})  # TODO\n",
    "  for tag1 in p_tag:\n",
    "    print(tag1.text)\n",
    "    \n",
    "\n",
    "find_parent_tags_with_beautifulsoup()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
